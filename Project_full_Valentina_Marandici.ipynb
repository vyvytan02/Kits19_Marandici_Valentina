{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2HqyFgnZl7L5"
      },
      "outputs": [],
      "source": [
        "import nibabel as nib\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.ndimage import zoom\n",
        "from statistics import mean\n",
        "from skimage.transform import resize\n",
        "import glob\n",
        "import PIL\n",
        "import copy\n",
        "import cv2\n",
        "import csv\n",
        "from tqdm import tqdm\n",
        "from skimage import io, color, transform\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Wwp5Y6HxaJO",
        "outputId": "cd2622c3-d5c3-4b7b-96d9-aadd561e555c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KQBri_xsmB7L"
      },
      "outputs": [],
      "source": [
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)"
      ],
      "metadata": {
        "id": "YW2ouqPlQrv8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0EwjMSGmD1h",
        "outputId": "16d590ea-73c6-46ff-d9f7-413acc42e056"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow "
      ],
      "metadata": {
        "id": "u2P4hI_lc19i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "JLttZRh5fX8X"
      },
      "outputs": [],
      "source": [
        "#@title Visualizing information about one image\n",
        "img = nib.load('/content/drive/MyDrive/og_pazienti/case_00074/imaging_middle.nii.gz')\n",
        "\n",
        "print(img.shape)\n",
        "print(img.get_data_dtype())\n",
        "print(img.header)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Resizing"
      ],
      "metadata": {
        "id": "W84BcTlr-rex"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCWeH12Epdrq"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPQ9-04RAcp3"
      },
      "outputs": [],
      "source": [
        "# Middle slice picking\n",
        "\n",
        "import os\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "\n",
        "og_path = '/content/drive/MyDrive/og_pazienti'\n",
        "\n",
        "def extract_middle_slice(img_path, mask_path):\n",
        "    img = nib.load(img_path).get_fdata()\n",
        "    mask = nib.load(mask_path).get_fdata()\n",
        "\n",
        "    # Get the middle slice index of the first dimension\n",
        "    slice_index = img.shape[0] // 2\n",
        "\n",
        "    # Extract the middle slice from the image and segmentation\n",
        "    img_middle_slice = img[slice_index, :, :]\n",
        "    mask_middle_slice = mask[slice_index, :, :]\n",
        "\n",
        "    return img_middle_slice, mask_middle_slice\n",
        "\n",
        "def process_subfolders(og_path):\n",
        "    for case_folder in os.listdir(og_path):\n",
        "        case_path = os.path.join(og_path, case_folder)\n",
        "        img_path = os.path.join(case_path, \"imaging.nii.gz\")\n",
        "        mask_path = os.path.join(case_path, \"segmentation.nii.gz\")\n",
        "\n",
        "        if not os.path.isfile(img_path) or not os.path.isfile(mask_path):\n",
        "            continue  # Skip if the image or mask file is missing\n",
        "\n",
        "        img_middle_slice, mask_middle_slice = extract_middle_slice(img_path, mask_path)\n",
        "\n",
        "        # Save the middle slice image to the original subfolder\n",
        "        img_out_path = os.path.join(case_path, \"imaging_middle.nii.gz\")\n",
        "        nib.save(nib.Nifti1Image(img_middle_slice, affine=None), img_out_path)\n",
        "\n",
        "        # Save the middle slice segmentation to the original subfolder\n",
        "        mask_out_path = os.path.join(case_path, \"segmentation_middle.nii.gz\")\n",
        "        nib.save(nib.Nifti1Image(mask_middle_slice, affine=None), mask_out_path)\n",
        "\n",
        "        # Delete the old image and segmentation files\n",
        "        os.remove(img_path)\n",
        "        os.remove(mask_path)\n",
        "\n",
        "# Call the function to process each subfolder\n",
        "process_subfolders(og_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "uCidYFWhfnic",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "45ae4495-274e-4fcc-e76a-9935af0b0b42"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-6a7080044194>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mimg_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_fdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mimg_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_data\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Remove any extra dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mimg_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSIZE_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSIZE_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mout_img_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_img_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".nii.gz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
          ]
        }
      ],
      "source": [
        "# Resizing\n",
        "\n",
        "SIZE_X = 256\n",
        "SIZE_Y = 256\n",
        "\n",
        "main_folder = '/content/drive/MyDrive/og_pazienti'\n",
        "out_img_dir = '/content/drive/MyDrive/resized_img'\n",
        "out_mask_dir = '/content/drive/MyDrive/resized_seg'\n",
        "\n",
        "os.makedirs(out_img_dir, exist_ok=True)\n",
        "os.makedirs(out_mask_dir, exist_ok=True)\n",
        "\n",
        "for subfolder in os.listdir(main_folder):\n",
        "    subfolder_path = os.path.join(main_folder, subfolder)\n",
        "    img_path = os.path.join(subfolder_path, \"imaging_middle.nii.gz\")\n",
        "    mask_path = os.path.join(subfolder_path, \"segmentation_middle.nii.gz\")\n",
        "    \n",
        "    if os.path.isfile(img_path) and os.path.isfile(mask_path):\n",
        "        img_data = nib.load(img_path).get_fdata()\n",
        "        img_data = np.squeeze(img_data) \n",
        "        img_data = cv2.resize(img_data, (SIZE_Y, SIZE_X))\n",
        "        \n",
        "        out_img_path = os.path.join(out_img_dir, subfolder + \".nii.gz\")\n",
        "        nib.save(nib.Nifti1Image(img_data, affine=None), out_img_path)\n",
        "\n",
        "        mask_data = nib.load(mask_path).get_fdata()\n",
        "        mask_data = np.squeeze(mask_data)  \n",
        "        mask_data = cv2.resize(mask_data, (SIZE_Y, SIZE_X), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        out_mask_path = os.path.join(out_mask_dir, subfolder + \".nii.gz\")\n",
        "        nib.save(nib.Nifti1Image(mask_data, affine=None), out_mask_path)\n",
        "\n",
        "\n",
        "img_files = os.listdir(out_img_dir)\n",
        "for img_file in img_files:\n",
        "    img_path = os.path.join(out_img_dir, img_file)\n",
        "    img_data = nib.load(img_path).get_fdata()\n",
        "    print(f\"Image: {img_file} | Dimensions: {img_data.shape}\")\n",
        "seg_files = os.listdir(out_mask_dir)\n",
        "for seg_file in seg_files:\n",
        "    seg_path = os.path.join(out_mask_dir, seg_file)\n",
        "    seg_data = nib.load(seg_path).get_fdata()\n",
        "    print(f\"Segmentation: {seg_file} | Dimensions: {seg_data.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QO9sHMod014B"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jU5XxfypepYP"
      },
      "outputs": [],
      "source": [
        "#Function for resized images visualization\n",
        "\n",
        "def display_resized_images(img_dir, mask_dir):\n",
        "    img_files = os.listdir(img_dir)\n",
        "    num_images = len(img_files)\n",
        "    num_columns = 5\n",
        "    num_rows = -(-num_images // num_columns)  # Round up division\n",
        "\n",
        "    fig = plt.figure(figsize=(20, num_rows * 4))\n",
        "    grid = ImageGrid(fig, 111, nrows_ncols=(num_rows, num_columns), axes_pad=0.5)\n",
        "\n",
        "    for i, img_file in enumerate(img_files):\n",
        "        img_path = os.path.join(img_dir, img_file)\n",
        "        mask_path = os.path.join(mask_dir, img_file)\n",
        "        img_data = nib.load(img_path).get_fdata()\n",
        "        mask_data = nib.load(mask_path).get_fdata()\n",
        "\n",
        "        ax = grid[i]\n",
        "        ax.imshow(img_data, cmap='gray')\n",
        "        ax.imshow(mask_data, cmap='jet', alpha=0.3)\n",
        "        ax.set_title(img_file)\n",
        "        ax.axis('off')\n",
        "\n",
        "  \n",
        "    plt.show()\n",
        "\n",
        "display_resized_images(out_img_dir, out_mask_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2yVgb_s28qn",
        "outputId": "2eecb5ec-114b-428c-df2f-6b678f19aff2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size Images: (101, 256, 256)\n",
            "Size Segmentations: (101, 256, 256)\n"
          ]
        }
      ],
      "source": [
        "#loaded_img and loaded_seg lists to np.array\n",
        "\n",
        "loaded_img = []\n",
        "loaded_seg = []\n",
        "\n",
        "for case_folder in os.listdir(out_img_dir):\n",
        "    img_path = os.path.join(out_img_dir, case_folder)\n",
        "    mask_path = os.path.join(out_mask_dir, case_folder)\n",
        "    \n",
        "    if not os.path.isfile(img_path) or not os.path.isfile(mask_path):\n",
        "        continue  \n",
        "\n",
        "    img = nib.load(img_path).get_fdata()\n",
        "    mask = nib.load(mask_path).get_fdata()\n",
        "    \n",
        "    loaded_img.append(img)\n",
        "    loaded_seg.append(mask)\n",
        "loaded_img = np.array(loaded_img)\n",
        "loaded_seg = np.array(loaded_seg)\n",
        "\n",
        "print(\"Size Images:\", loaded_img.shape)\n",
        "print(\"Size Segmentations:\", loaded_seg.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATCFK5BZsj-H",
        "outputId": "d20b4c96-249a-4bb3-b321-81b2ee67622f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The masks are labeled with three classes: background, kidney, and tumor.\n",
            "Unique values in the masks array: [0. 1. 2.]\n"
          ]
        }
      ],
      "source": [
        "# Checking the classes of the masks\n",
        "\n",
        "unique_classes = np.unique(loaded_seg)\n",
        "\n",
        "if len(unique_classes) == 3 and 0 in unique_classes and 1 in unique_classes and 2 in unique_classes:\n",
        "    print(\"The masks are labeled with three classes: background, kidney, and tumor.\")\n",
        "else:\n",
        "    print(\"The masks are not properly labeled with three classes.\")\n",
        "\n",
        "unique_values = np.unique(loaded_seg)\n",
        "print(\"Unique values in the masks array:\", unique_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbZOsZ6lbR-q"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28W2kewC6yN3"
      },
      "outputs": [],
      "source": [
        "# Random seed for reproducibility\n",
        "seed = 42\n",
        "\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qnmSgGog1Qwo"
      },
      "outputs": [],
      "source": [
        "#@title Model: multi_unet\n",
        "n_classes = 3\n",
        "kernel_initializer =  'he_uniform'\n",
        "\n",
        "################################################################\n",
        "def multi_unet_model(n_classes=3, IMG_HEIGHT=256, IMG_WIDTH=256, IMG_CHANNELS=1):\n",
        "#Build the model\n",
        "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "    s = Lambda(lambda x: x / 255)(inputs) \n",
        "    s = inputs\n",
        "\n",
        "    #Contraction path\n",
        "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same', kernel_regularizer=regularizers.l1_l2(l1=0.005, l2=0.01))(s)\n",
        "    c1 = Dropout(0.1)(c1)\n",
        "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "    \n",
        "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same', kernel_regularizer=regularizers.l2(l2=0.005))(p1)\n",
        "    c2 = Dropout(0.1)(c2)\n",
        "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "     \n",
        "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
        "    c3 = Dropout(0.2)(c3)\n",
        "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "     \n",
        "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
        "    c4 = Dropout(0.2)(c4)\n",
        "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
        "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "     \n",
        "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
        "    c5 = Dropout(0.3)(c5)\n",
        "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
        "    \n",
        "    #Expansive path \n",
        "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
        "    c6 = Dropout(0.2)(c6)\n",
        "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
        "     \n",
        "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
        "    c7 = Dropout(0.2)(c7)\n",
        "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
        "     \n",
        "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
        "    c8 = Dropout(0.1)(c8)\n",
        "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
        "     \n",
        "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = concatenate([u9, c1], axis=3)\n",
        "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
        "    c9 = Dropout(0.1)(c9)\n",
        "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
        "     \n",
        "    outputs = Conv2D(n_classes, (1, 1), activation='softmax')(c9)\n",
        "     \n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    \n",
        "    return model\n",
        "\n",
        "#model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting and One-hot Encoding"
      ],
      "metadata": {
        "id": "lfhkugmS-esL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOqMr2j_CpDi",
        "outputId": "33e2a6db-c000-4ca5-e21f-3c25ff808304"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 60\n",
            "Validation set size: 20\n",
            "Test set size: 21\n"
          ]
        }
      ],
      "source": [
        "# Splitting into Validation Training and Test\n",
        "train_ratio = 0.6\n",
        "val_ratio = 0.2\n",
        "test_ratio = 0.2\n",
        "loaded_img = np.array(loaded_img)\n",
        "loaded_seg = np.array(loaded_seg)\n",
        "\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(loaded_img, loaded_seg, test_size=test_ratio, random_state=42)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_val, y_train_val, test_size=val_ratio/(1 - test_ratio), random_state=42\n",
        ")\n",
        "print(\"Train set size:\", X_train.shape[0])\n",
        "print(\"Validation set size:\", X_val.shape[0])\n",
        "print(\"Test set size:\", X_test.shape[0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "vwQOqVJfGRXN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bd58173-20f5-447e-cc6d-b6c5e2b0131c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (60, 256, 256, 1)\n",
            "X_val shape: (20, 256, 256, 1)\n",
            "X_test shape: (21, 256, 256, 1)\n",
            "y_train shape: (60, 256, 256, 1)\n",
            "y_val shape: (20, 256, 256, 1)\n",
            "y_test shape: (21, 256, 256, 1)\n"
          ]
        }
      ],
      "source": [
        "X_train = np.expand_dims(X_train, axis=3)\n",
        "X_val = np.expand_dims(X_val, axis=3)\n",
        "X_test = np.expand_dims(X_test, axis=3)\n",
        "y_train = np.expand_dims(y_train, axis=3)\n",
        "y_val = np.expand_dims(y_val, axis=3)\n",
        "y_test = np.expand_dims(y_test, axis=3)\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_val shape:\", X_val.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_val shape:\", y_val.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "a8aMYDwHZ-5G"
      },
      "outputs": [],
      "source": [
        "#One hot encoding on y_train\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes=3)\n",
        "y_test = to_categorical(y_test, num_classes=3)\n",
        "y_val = to_categorical(y_val, num_classes=3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ytd5M83NBMV"
      },
      "source": [
        "## Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "I8yHumCfMyAL"
      },
      "outputs": [],
      "source": [
        "def augment_data(X_train, y_train):\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=30,  \n",
        "        width_shift_range=0.2,  \n",
        "        height_shift_range=0.2, \n",
        "        zoom_range=0.3,  \n",
        "        horizontal_flip=True,  \n",
        "        fill_mode='nearest'  \n",
        "    )\n",
        "\n",
        "    augmented_images = []\n",
        "    augmented_masks = []\n",
        "\n",
        "    for i in range(len(X_train)):\n",
        "        image = X_train[i]\n",
        "        mask = y_train[i]\n",
        "\n",
        "        concatenated = np.concatenate((image, mask), axis=2)\n",
        "        concatenated = concatenated.reshape((1,) + concatenated.shape)\n",
        "        aug_iter = datagen.flow(concatenated, batch_size=1)\n",
        "        augmented = next(aug_iter)\n",
        "        augmented_image = augmented[..., :1]\n",
        "        augmented_mask = augmented[..., 1:]\n",
        "        augmented_images.append(augmented_image[0])\n",
        "        augmented_masks.append(augmented_mask[0])\n",
        "    augmented_images = np.array(augmented_images)\n",
        "    augmented_masks = np.array(augmented_masks)\n",
        "\n",
        "    return augmented_images, augmented_masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QglQEstITqT5",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Augmented Data Display\n",
        "def display_augmented_data(X_train_augmented, y_train_augmented, num_samples=3):\n",
        "    sample_indices = random.sample(range(len(X_train_augmented)), min(num_samples, 9))\n",
        "    fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
        "    fig.subplots_adjust(hspace=0.4)\n",
        "\n",
        "    for i, idx in enumerate(sample_indices):\n",
        "        row = i // 3\n",
        "        col = i % 3\n",
        "\n",
        "        image = X_train_augmented[idx]\n",
        "        mask = y_train_augmented[idx]\n",
        "\n",
        "        axes[row, col].imshow(image[..., 0], cmap='gray')\n",
        "        axes[row, col].axis('off')\n",
        "        axes[row, col].imshow(mask[..., 0], alpha=0.5, cmap='jet')\n",
        "\n",
        "    for j in range(num_samples, 9):\n",
        "        row = j // 3\n",
        "        col = j % 3\n",
        "        axes[row, col].axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "X_train_augmented, y_train_augmented = augment_data(X_train, y_train)\n",
        "display_augmented_data(X_train_augmented, y_train_augmented, num_samples=9)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Loading"
      ],
      "metadata": {
        "id": "kzekYJus1w_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loading(X_train, y_train, X_train_augmented, y_train_augmented, num_augmented=20):\n",
        "    indices = np.arange(len(X_train))\n",
        "    np.random.shuffle(indices)\n",
        "    original_indices = indices\n",
        "    augmented_indices = np.random.choice(len(X_train_augmented), num_augmented)\n",
        "    original_images = X_train[original_indices]\n",
        "    original_masks = y_train[original_indices]\n",
        "    augmented_images = X_train_augmented[augmented_indices]\n",
        "    augmented_masks = y_train_augmented[augmented_indices]\n",
        "    X_train_full = np.concatenate([original_images, augmented_images], axis=0)\n",
        "    y_train_full = np.concatenate([original_masks, augmented_masks], axis=0)\n",
        "\n",
        "    return X_train_full, y_train_full"
      ],
      "metadata": {
        "id": "MGqz3FzUzyrb"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizing final training Dataset\n",
        "def visualize_random_samples(images, masks, num_samples=5):\n",
        "    sample_indices = random.sample(range(len(images)), num_samples)\n",
        "\n",
        "    fig, axes = plt.subplots(num_samples, 2, figsize=(8, 8))\n",
        "    for i, idx in enumerate(sample_indices):\n",
        "        image = images[idx]\n",
        "        mask = masks[idx]\n",
        "\n",
        "        # Plot the image\n",
        "        axes[i, 0].imshow(image, cmap='gray')\n",
        "        axes[i, 0].axis('off')\n",
        "        axes[i, 0].set_title('Image')\n",
        "\n",
        "        # Plot the mask\n",
        "        axes[i, 1].imshow(mask, cmap='gray')\n",
        "        axes[i, 1].axis('off')\n",
        "        axes[i, 1].set_title('Mask')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Assuming you have loaded your dataset into X_train_full and y_train_full\n",
        "visualize_random_samples(X_train_full, y_train_full, num_samples=5)"
      ],
      "metadata": {
        "id": "QNLlTBQp_d7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for weighted losses\n",
        "def weighted_loss(class_weights):\n",
        "    def loss(y_true, y_pred):\n",
        "        y_true = tf.argmax(y_true, axis=-1)\n",
        "        class_weights_tensor = tf.convert_to_tensor(list(class_weights.values()), dtype=tf.float32)\n",
        "        weights = tf.gather(class_weights_tensor, y_true)\n",
        "        loss_value = tf.keras.losses.SparseCategoricalCrossentropy()(y_true, y_pred, sample_weight=weights)\n",
        "        \n",
        "        return loss_value\n",
        "    return loss"
      ],
      "metadata": {
        "id": "FYXTvGEyMCCE"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Evaluation"
      ],
      "metadata": {
        "id": "NYOxWZhr-CTR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCG3FneGMi1D",
        "cellView": "code"
      },
      "outputs": [],
      "source": [
        "\n",
        "n_classes = 3\n",
        "IMG_HEIGHT = 256\n",
        "IMG_WIDTH  = 256\n",
        "IMG_CHANNELS = 1\n",
        "\n",
        "checkpoint_filepath = '/content/drive/MyDrive/models/checkpoints/model_checkpoint.hdf5'\n",
        "\n",
        "def get_model():\n",
        "    model = multi_unet_model(n_classes=n_classes, IMG_HEIGHT=IMG_HEIGHT, IMG_WIDTH=IMG_WIDTH, IMG_CHANNELS=IMG_CHANNELS)\n",
        "    return model\n",
        "\n",
        "model = get_model()\n",
        "model.compile(optimizer = Adam(learning_rate = 1e-3),loss=weighted_loss(class_weights_dict), metrics=['accuracy'])\n",
        "#model.summary()\n",
        "X_train_full, y_train_full = train_loading(X_train, y_train, X_train_augmented, y_train_augmented)\n",
        "\n",
        "checkpoint_filepath = '/content/drive/MyDrive/models/checkpoints/model_checkpoint.hdf5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(checkpoint_filepath, \n",
        "                             monitor='loss', \n",
        "                             save_best_only=True, \n",
        "                             mode='min', \n",
        "                             verbose=1)\n",
        "#for pre-trained weights. \n",
        "#model.load_weights('')\n",
        "\n",
        "history = model.fit(X_train_full, y_train_full, \n",
        "                    batch_size = 16, \n",
        "                    verbose=1, \n",
        "                    epochs=110, \n",
        "                    validation_data=(X_val, y_val), \n",
        "                    #class_weight=class_weights,\n",
        "                    shuffle=True,\n",
        "                    callbacks=[checkpoint])\n",
        "                   \n",
        "model.save('test.hdf5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRiAc8m_FJr-"
      },
      "outputs": [],
      "source": [
        "\n",
        "_, acc = model.evaluate(X_test, y_test)\n",
        "print(\"Accuracy is = \", (acc * 100.0), \"%\")\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "plt.plot(epochs, acc, 'y', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
        "plt.title('Training and validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "wyhiUk1Y-GdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "_, acc = model.evaluate(X_test, y_test)\n",
        "print(\"Accuracy is = \", (acc * 100.0), \"%\")\n",
        "\n",
        "# Select a random image from the test dataset\n",
        "index = np.random.randint(len(X_test))\n",
        "test_image = X_test[index]\n",
        "ground_truth = y_test[index]\n",
        "\n",
        "test_image = np.reshape(test_image, (1,) + test_image.shape)\n",
        "predicted_mask = model.predict(test_image)\n",
        "\n",
        "predicted_labels = np.argmax(predicted_mask, axis=-1)\n",
        "ground_truth_labels = np.argmax(ground_truth, axis=-1)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(test_image[0])\n",
        "plt.title(\"Original Image\")\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(ground_truth_labels, cmap='gray')\n",
        "plt.title(\"Ground Truth\")\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(predicted_labels[0], cmap='gray')\n",
        "plt.title(\"Predicted Segmentation\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TWCw239SiabC",
        "cellView": "code"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}